{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processing language: java ===\n",
      "Columns in training set: ['index', 'class', 'comment_sentence', 'partition', 'combo', 'labels']\n",
      "First training example: {'index': 0, 'class': 'Abfss.java', 'comment_sentence': 'azure blob file system implementation of abstractfilesystem.', 'partition': 0, 'combo': 'azure blob file system implementation of abstractfilesystem. | Abfss.java', 'labels': [1, 0, 0, 0, 0, 0, 0]}\n",
      "All labels: ['summary', 'Ownership', 'Expand', 'usage', 'Pointer', 'deprecation', 'rational']\n",
      "Label2ID: {'summary': 0, 'Ownership': 1, 'Expand': 2, 'usage': 3, 'Pointer': 4, 'deprecation': 5, 'rational': 6}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b653ff4f81584eeba98faa29ac548991",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7614 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d166794b497248349eb1a7433ebb0937",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1725 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02c726f9e3df4cadb33a0228fb618b50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/7614 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e48710c0e244a5eab15d4304b9bc074",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/1725 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_labels: 7\n",
      "Shape of a sample's label vector: torch.Size([7])\n",
      "Dtype of a sample's label vector: torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/var/folders/jd/21sqkph55plf4340061c7gg40000gn/T/ipykernel_94999/1379641631.py:137: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training for language: java\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0108ac137dc4470b8046b01904bc95d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/952 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1631, 'grad_norm': 0.5765820145606995, 'learning_rate': 2.373949579831933e-05, 'epoch': 0.53}\n",
      "{'train_runtime': 2473.7667, 'train_samples_per_second': 3.078, 'train_steps_per_second': 0.385, 'train_loss': 0.13865949726906143, 'epoch': 1.0}\n",
      "Training done for language: java\n",
      "Running evaluation on the test set for java...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b1911c2101f498b9eed2e2ac7623eef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/216 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results for java: {'eval_loss': 0.12433961778879166, 'eval_accuracy': 0.8034782608695652, 'eval_micro_precision': 0.8865519439133206, 'eval_micro_recall': 0.8008059873344847, 'eval_micro_f1': 0.8415003024803388, 'eval_summary_precision': 0.8887688984881209, 'eval_summary_recall': 0.922645739910314, 'eval_summary_f1': 0.9053905390539054, 'eval_Ownership_precision': 1.0, 'eval_Ownership_recall': 1.0, 'eval_Ownership_f1': 1.0, 'eval_Expand_precision': 0.5, 'eval_Expand_recall': 0.058823529411764705, 'eval_Expand_f1': 0.10526315789473684, 'eval_usage_precision': 0.9010695187165776, 'eval_usage_recall': 0.7819025522041764, 'eval_usage_f1': 0.8372670807453416, 'eval_Pointer_precision': 0.8848167539267016, 'eval_Pointer_recall': 0.9184782608695652, 'eval_Pointer_f1': 0.9013333333333333, 'eval_deprecation_precision': 1.0, 'eval_deprecation_recall': 0.6, 'eval_deprecation_f1': 0.75, 'eval_rational_precision': 0.16666666666666666, 'eval_rational_recall': 0.029411764705882353, 'eval_rational_f1': 0.05, 'eval_runtime': 70.8859, 'eval_samples_per_second': 24.335, 'eval_steps_per_second': 3.047, 'epoch': 1.0}\n",
      "\n",
      "=== Processing language: python ===\n",
      "Columns in training set: ['index', 'class', 'comment_sentence', 'partition', 'combo', 'labels']\n",
      "First training example: {'index': 1, 'class': 'AccessMixin', 'comment_sentence': 'functionality.', 'partition': 0, 'combo': 'functionality. | AccessMixin', 'labels': [0, 0, 0, 0, 1]}\n",
      "All labels: ['Usage', 'Parameters', 'DevelopmentNotes', 'Expand', 'Summary']\n",
      "Label2ID: {'Usage': 0, 'Parameters': 1, 'DevelopmentNotes': 2, 'Expand': 3, 'Summary': 4}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2454a20421e8419e9f0ee97a0bd43680",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1884 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dffde98bc95146fc897589b6d4c5a43a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/406 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35d96818869b4a2abb655599f9f4bce3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/1884 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3b0a197d15949c3a0b105651f994a57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/406 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_labels: 5\n",
      "Shape of a sample's label vector: torch.Size([5])\n",
      "Dtype of a sample's label vector: torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/var/folders/jd/21sqkph55plf4340061c7gg40000gn/T/ipykernel_94999/1379641631.py:137: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training for language: python\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42f605ac83a44c9a9dfcbbb591179e19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/236 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 170.0886, 'train_samples_per_second': 11.077, 'train_steps_per_second': 1.388, 'train_loss': 0.4555435827222921, 'epoch': 1.0}\n",
      "Training done for language: python\n",
      "Running evaluation on the test set for python...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0a654f2fd1f4cd19081d23a36d8fb02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/51 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results for python: {'eval_loss': 0.41218048334121704, 'eval_accuracy': 0.33497536945812806, 'eval_micro_precision': 0.7526881720430108, 'eval_micro_recall': 0.3211009174311927, 'eval_micro_f1': 0.45016077170418006, 'eval_Usage_precision': 0.7605633802816901, 'eval_Usage_recall': 0.4462809917355372, 'eval_Usage_f1': 0.5625, 'eval_Parameters_precision': 0.7551020408163265, 'eval_Parameters_recall': 0.2890625, 'eval_Parameters_f1': 0.4180790960451977, 'eval_DevelopmentNotes_precision': 0.0, 'eval_DevelopmentNotes_recall': 0.0, 'eval_DevelopmentNotes_f1': 0.0, 'eval_Expand_precision': 0.0, 'eval_Expand_recall': 0.0, 'eval_Expand_f1': 0.0, 'eval_Summary_precision': 0.7424242424242424, 'eval_Summary_recall': 0.5975609756097561, 'eval_Summary_f1': 0.6621621621621622, 'eval_runtime': 4.2252, 'eval_samples_per_second': 96.09, 'eval_steps_per_second': 12.07, 'epoch': 1.0}\n",
      "\n",
      "=== Processing language: pharo ===\n",
      "Columns in training set: ['index', 'class', 'comment_sentence', 'partition', 'combo', 'labels']\n",
      "First training example: {'index': 0, 'class': 'BlAnchorRelativeToElement', 'comment_sentence': 'relative anchor takes an arbitrary element as a reference an compute its position based on properties of that element.', 'partition': 0, 'combo': 'relative anchor takes an arbitrary element as a reference an compute its position based on properties of that element. | BlAnchorRelativeToElement', 'labels': [0, 0, 1, 0, 0, 0, 0]}\n",
      "All labels: ['Keyimplementationpoints', 'Example', 'Responsibilities', 'Classreferences', 'Intent', 'Keymessages', 'Collaborators']\n",
      "Label2ID: {'Keyimplementationpoints': 0, 'Example': 1, 'Responsibilities': 2, 'Classreferences': 3, 'Intent': 4, 'Keymessages': 5, 'Collaborators': 6}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04c662f3034c4e1e9cf78f315a392acf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1298 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59e23646f021465da1d6106c58155211",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/289 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8173cf92b40493aa5130be026532263",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/1298 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11b8c5f0904442a3be347ece4d356606",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/289 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_labels: 7\n",
      "Shape of a sample's label vector: torch.Size([7])\n",
      "Dtype of a sample's label vector: torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/var/folders/jd/21sqkph55plf4340061c7gg40000gn/T/ipykernel_94999/1379641631.py:137: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training for language: pharo\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2639057bff3f4c4bb409701db28f43cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/163 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 175.7398, 'train_samples_per_second': 7.386, 'train_steps_per_second': 0.928, 'train_loss': 0.36342822115845475, 'epoch': 1.0}\n",
      "Training done for language: pharo\n",
      "Running evaluation on the test set for pharo...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f23403847714b4286fe075dce2282ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results for pharo: {'eval_loss': 0.27968451380729675, 'eval_accuracy': 0.36678200692041524, 'eval_micro_precision': 0.7371794871794872, 'eval_micro_recall': 0.38205980066445183, 'eval_micro_f1': 0.5032822757111597, 'eval_Keyimplementationpoints_precision': 0.0, 'eval_Keyimplementationpoints_recall': 0.0, 'eval_Keyimplementationpoints_f1': 0.0, 'eval_Example_precision': 0.732824427480916, 'eval_Example_recall': 0.8067226890756303, 'eval_Example_f1': 0.768, 'eval_Responsibilities_precision': 0.5384615384615384, 'eval_Responsibilities_recall': 0.1346153846153846, 'eval_Responsibilities_f1': 0.2153846153846154, 'eval_Classreferences_precision': 0.0, 'eval_Classreferences_recall': 0.0, 'eval_Classreferences_f1': 0.0, 'eval_Intent_precision': 1.0, 'eval_Intent_recall': 0.4, 'eval_Intent_f1': 0.5714285714285714, 'eval_Keymessages_precision': 0.0, 'eval_Keymessages_recall': 0.0, 'eval_Keymessages_f1': 0.0, 'eval_Collaborators_precision': 0.0, 'eval_Collaborators_recall': 0.0, 'eval_Collaborators_f1': 0.0, 'eval_runtime': 5.2943, 'eval_samples_per_second': 54.587, 'eval_steps_per_second': 6.989, 'epoch': 1.0}\n",
      "\n",
      "=== Summary of Results for All Languages ===\n",
      "Language: java\n",
      "  eval_loss: 0.12433961778879166\n",
      "  eval_accuracy: 0.8034782608695652\n",
      "  eval_micro_precision: 0.8865519439133206\n",
      "  eval_micro_recall: 0.8008059873344847\n",
      "  eval_micro_f1: 0.8415003024803388\n",
      "  eval_summary_precision: 0.8887688984881209\n",
      "  eval_summary_recall: 0.922645739910314\n",
      "  eval_summary_f1: 0.9053905390539054\n",
      "  eval_Ownership_precision: 1.0\n",
      "  eval_Ownership_recall: 1.0\n",
      "  eval_Ownership_f1: 1.0\n",
      "  eval_Expand_precision: 0.5\n",
      "  eval_Expand_recall: 0.058823529411764705\n",
      "  eval_Expand_f1: 0.10526315789473684\n",
      "  eval_usage_precision: 0.9010695187165776\n",
      "  eval_usage_recall: 0.7819025522041764\n",
      "  eval_usage_f1: 0.8372670807453416\n",
      "  eval_Pointer_precision: 0.8848167539267016\n",
      "  eval_Pointer_recall: 0.9184782608695652\n",
      "  eval_Pointer_f1: 0.9013333333333333\n",
      "  eval_deprecation_precision: 1.0\n",
      "  eval_deprecation_recall: 0.6\n",
      "  eval_deprecation_f1: 0.75\n",
      "  eval_rational_precision: 0.16666666666666666\n",
      "  eval_rational_recall: 0.029411764705882353\n",
      "  eval_rational_f1: 0.05\n",
      "  eval_runtime: 70.8859\n",
      "  eval_samples_per_second: 24.335\n",
      "  eval_steps_per_second: 3.047\n",
      "  epoch: 1.0\n",
      "\n",
      "Language: python\n",
      "  eval_loss: 0.41218048334121704\n",
      "  eval_accuracy: 0.33497536945812806\n",
      "  eval_micro_precision: 0.7526881720430108\n",
      "  eval_micro_recall: 0.3211009174311927\n",
      "  eval_micro_f1: 0.45016077170418006\n",
      "  eval_Usage_precision: 0.7605633802816901\n",
      "  eval_Usage_recall: 0.4462809917355372\n",
      "  eval_Usage_f1: 0.5625\n",
      "  eval_Parameters_precision: 0.7551020408163265\n",
      "  eval_Parameters_recall: 0.2890625\n",
      "  eval_Parameters_f1: 0.4180790960451977\n",
      "  eval_DevelopmentNotes_precision: 0.0\n",
      "  eval_DevelopmentNotes_recall: 0.0\n",
      "  eval_DevelopmentNotes_f1: 0.0\n",
      "  eval_Expand_precision: 0.0\n",
      "  eval_Expand_recall: 0.0\n",
      "  eval_Expand_f1: 0.0\n",
      "  eval_Summary_precision: 0.7424242424242424\n",
      "  eval_Summary_recall: 0.5975609756097561\n",
      "  eval_Summary_f1: 0.6621621621621622\n",
      "  eval_runtime: 4.2252\n",
      "  eval_samples_per_second: 96.09\n",
      "  eval_steps_per_second: 12.07\n",
      "  epoch: 1.0\n",
      "\n",
      "Language: pharo\n",
      "  eval_loss: 0.27968451380729675\n",
      "  eval_accuracy: 0.36678200692041524\n",
      "  eval_micro_precision: 0.7371794871794872\n",
      "  eval_micro_recall: 0.38205980066445183\n",
      "  eval_micro_f1: 0.5032822757111597\n",
      "  eval_Keyimplementationpoints_precision: 0.0\n",
      "  eval_Keyimplementationpoints_recall: 0.0\n",
      "  eval_Keyimplementationpoints_f1: 0.0\n",
      "  eval_Example_precision: 0.732824427480916\n",
      "  eval_Example_recall: 0.8067226890756303\n",
      "  eval_Example_f1: 0.768\n",
      "  eval_Responsibilities_precision: 0.5384615384615384\n",
      "  eval_Responsibilities_recall: 0.1346153846153846\n",
      "  eval_Responsibilities_f1: 0.2153846153846154\n",
      "  eval_Classreferences_precision: 0.0\n",
      "  eval_Classreferences_recall: 0.0\n",
      "  eval_Classreferences_f1: 0.0\n",
      "  eval_Intent_precision: 1.0\n",
      "  eval_Intent_recall: 0.4\n",
      "  eval_Intent_f1: 0.5714285714285714\n",
      "  eval_Keymessages_precision: 0.0\n",
      "  eval_Keymessages_recall: 0.0\n",
      "  eval_Keymessages_f1: 0.0\n",
      "  eval_Collaborators_precision: 0.0\n",
      "  eval_Collaborators_recall: 0.0\n",
      "  eval_Collaborators_f1: 0.0\n",
      "  eval_runtime: 5.2943\n",
      "  eval_samples_per_second: 54.587\n",
      "  eval_steps_per_second: 6.989\n",
      "  epoch: 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from datasets import load_dataset, Features, Sequence, Value\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "MODEL_NAME = \"distilbert-base-uncased\"\n",
    "\n",
    "language_categories = {\n",
    "    \"java\": [\"summary\", \"Ownership\", \"Expand\", \"usage\", \"Pointer\", \"deprecation\", \"rational\"],\n",
    "    \"python\": [\"Usage\", \"Parameters\", \"DevelopmentNotes\", \"Expand\", \"Summary\"],\n",
    "    \"pharo\": [\"Keyimplementationpoints\", \"Example\", \"Responsibilities\", \"Classreferences\", \"Intent\", \"Keymessages\", \"Collaborators\"]\n",
    "}\n",
    "\n",
    "dataset_name = \"NLBSE/nlbse25-code-comment-classification\"\n",
    "languages = [\"java\", \"python\", \"pharo\"]\n",
    "\n",
    "all_results = {}\n",
    "\n",
    "for lang in languages:\n",
    "    all_labels = language_categories[lang]\n",
    "    num_labels = len(all_labels)\n",
    "\n",
    "    print(f\"\\n=== Processing language: {lang} ===\")\n",
    "    raw_ds = load_dataset(dataset_name)\n",
    "    train_ds = raw_ds[f\"{lang}_train\"]\n",
    "    test_ds = raw_ds[f\"{lang}_test\"]\n",
    "\n",
    "    print(\"Columns in training set:\", train_ds.column_names)\n",
    "    print(\"First training example:\", train_ds[0])\n",
    "    print(\"All labels:\", all_labels)\n",
    "\n",
    "    label_map = {lbl: idx for idx, lbl in enumerate(all_labels)}\n",
    "    inverse_label_map = {idx: lbl for lbl, idx in label_map.items()}\n",
    "\n",
    "    print(\"label map:\", label_map)\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "    def encode_batch(examples):\n",
    "        encodings = tokenizer(\n",
    "            examples[\"comment_sentence\"],\n",
    "            truncation=True,\n",
    "            padding=True,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        labels = torch.tensor(examples[\"labels\"], dtype=torch.float32)\n",
    "        return {\n",
    "            \"input_ids\": encodings[\"input_ids\"],\n",
    "            \"attention_mask\": encodings[\"attention_mask\"],\n",
    "            \"labels\": labels\n",
    "        }\n",
    "\n",
    "    proc_train = train_ds.map(encode_batch, batched=True, batch_size=16)\n",
    "    proc_test = test_ds.map(encode_batch, batched=True, batch_size=16)\n",
    "\n",
    "    unused_columns = ['index', 'class', 'comment_sentence', 'partition', 'combo']\n",
    "    proc_train = proc_train.remove_columns(unused_columns)\n",
    "    proc_test = proc_test.remove_columns(unused_columns)\n",
    "\n",
    "    features = Features({\n",
    "        \"input_ids\": Sequence(Value(\"int64\")),\n",
    "        \"attention_mask\": Sequence(Value(\"int64\")),\n",
    "        \"labels\": Sequence(Value(\"float32\"))\n",
    "    })\n",
    "\n",
    "    proc_train = proc_train.cast(features)\n",
    "    proc_test = proc_test.cast(features)\n",
    "\n",
    "    proc_train.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "    proc_test.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "\n",
    "    print(\"num_labels:\", num_labels)\n",
    "    print(\"Shape of a sample's label vector:\", proc_train[0][\"labels\"].shape)\n",
    "    print(\"Dtype of a sample's label vector:\", proc_train[0][\"labels\"].dtype)\n",
    "\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        MODEL_NAME,\n",
    "        num_labels=num_labels,\n",
    "        problem_type=\"multi_label_classification\"\n",
    "    )\n",
    "\n",
    "    def compute_metrics(eval_pred):\n",
    "        predictions, labels = eval_pred\n",
    "        probs = 1 / (1 + np.exp(-predictions))\n",
    "        preds = (probs > 0.5).astype(int)\n",
    "\n",
    "        micro_precision, micro_recall, micro_f1, _ = precision_recall_fscore_support(\n",
    "            labels, preds, average='micro', zero_division=0\n",
    "        )\n",
    "        acc = accuracy_score(labels, preds)\n",
    "\n",
    "        per_cat_precision, per_cat_recall, per_cat_f1, _ = precision_recall_fscore_support(\n",
    "            labels, preds, average=None, zero_division=0\n",
    "        )\n",
    "\n",
    "        per_category_metrics = {}\n",
    "        for i, cat in enumerate(all_labels):\n",
    "            per_category_metrics[f\"{cat}_precision\"] = per_cat_precision[i]\n",
    "            per_category_metrics[f\"{cat}_recall\"] = per_cat_recall[i]\n",
    "            per_category_metrics[f\"{cat}_f1\"] = per_cat_f1[i]\n",
    "\n",
    "        metrics = {\n",
    "            \"accuracy\": acc,\n",
    "            \"micro_precision\": micro_precision,\n",
    "            \"micro_recall\": micro_recall,\n",
    "            \"micro_f1\": micro_f1\n",
    "        }\n",
    "        metrics.update(per_category_metrics)\n",
    "        return metrics\n",
    "\n",
    "    # (1 epoch for demonstration)\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=f\"./{lang}_results\",\n",
    "        evaluation_strategy=\"no\",\n",
    "        save_strategy=\"no\",\n",
    "        per_device_train_batch_size=8,\n",
    "        per_device_eval_batch_size=8,\n",
    "        num_train_epochs=1,\n",
    "        learning_rate=5e-5,\n",
    "        weight_decay=0.01,\n",
    "        logging_dir=f\"./{lang}_logs\"\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=proc_train,\n",
    "        eval_dataset=proc_test,\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics\n",
    "    )\n",
    "\n",
    "    print(\"Starting training for language:\", lang)\n",
    "    trainer.train()\n",
    "    print(\"Training done for language:\", lang)\n",
    "\n",
    "    print(f\"Running evaluation on the test set for {lang}...\")\n",
    "    results = trainer.evaluate()\n",
    "    print(f\"Evaluation results for {lang}:\", results)\n",
    "\n",
    "    all_results[lang] = results\n",
    "\n",
    "print(\"\\n=== Summary of Results for All Languages ===\")\n",
    "for lang, res in all_results.items():\n",
    "    print(f\"Language: {lang}\")\n",
    "    for k, v in res.items():\n",
    "        print(f\"  {k}: {v}\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
